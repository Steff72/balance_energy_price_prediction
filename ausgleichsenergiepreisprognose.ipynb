{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f24b826d",
   "metadata": {},
   "source": [
    "# Full Pipeline Notebook\n",
    "This notebook consolidates all repository code (except the tests) into one workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1efd803",
   "metadata": {},
   "source": [
    "## Imports and utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f1f989",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "try:\n",
    "    from entsoe import EntsoePandasClient\n",
    "except ImportError:\n",
    "    EntsoePandasClient = None\n",
    "\n",
    "try:\n",
    "    import holidays\n",
    "except ImportError:\n",
    "    holidays = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bef5e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BASE_URL = \"https://www.swissgrid.ch/dam/swissgrid/current/Data/excel/balancingenergy/\"\n",
    "\n",
    "def download_monthly_price(year: int, month: int, folder: Path = Path(\"data\")) -> Path:\n",
    "    \"\"\"Download a monthly balancing energy price file. If download fails a dummy file is created.\"\"\"\n",
    "    folder.mkdir(exist_ok=True)\n",
    "    filename = folder / f\"{year}_{month:02d}_balancing_energy_prices.xlsx\"\n",
    "    url = f\"{BASE_URL}{year}/{month:02d}/balancing_energy_prices_{year}_{month:02d}.xlsx\"\n",
    "    try:\n",
    "        r = requests.get(url, timeout=30)\n",
    "        r.raise_for_status()\n",
    "        filename.write_bytes(r.content)\n",
    "        print(f\"Downloaded {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not download {url}: {e}. Creating dummy data\")\n",
    "        dummy = pd.DataFrame({\n",
    "            'Time': pd.date_range(f\"{year}-{month:02d}-01\", periods=96, freq='15min'),\n",
    "            'PositivePrice': 0.0,\n",
    "            'NegativePrice': 0.0,\n",
    "        })\n",
    "        dummy.to_excel(filename, index=False)\n",
    "    return filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b228976",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_price_file(path: Path) -> pd.DataFrame:\n",
    "    df = pd.read_excel(path)\n",
    "    df = df.rename(columns=str.strip)\n",
    "    df['Time'] = pd.to_datetime(df['Time'])\n",
    "    return df.set_index('Time')\n",
    "\n",
    "\n",
    "def add_basic_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df['hour'] = df.index.hour\n",
    "    df['weekday'] = df.index.weekday\n",
    "    df['month'] = df.index.month\n",
    "    df['dayofyear'] = df.index.dayofyear\n",
    "    df['lag_price'] = df['PositivePrice'].shift(1)\n",
    "    df['rolling_mean_24h'] = df['PositivePrice'].rolling(window=24).mean()\n",
    "    df['rolling_std_24h'] = df['PositivePrice'].rolling(window=24).std()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fe4e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fetch_entsoe_load(start: datetime, end: datetime, token: str) -> pd.DataFrame:\n",
    "    if EntsoePandasClient is None:\n",
    "        raise RuntimeError('entsoe-py not installed')\n",
    "    client = EntsoePandasClient(api_key=token)\n",
    "    try:\n",
    "        load = client.query_load(country_code='CH', start=start, end=end)\n",
    "        return load.rename('load').to_frame()\n",
    "    except Exception as e:\n",
    "        print(f'Could not download ENTSO-E data: {e}. Returning dummy data')\n",
    "        idx = pd.date_range(start, end, freq='H', inclusive='left')\n",
    "        return pd.DataFrame({'load': 0.0}, index=idx)\n",
    "\n",
    "\n",
    "def fetch_weather(start: datetime, end: datetime, lat: float, lon: float) -> pd.DataFrame:\n",
    "    url = (\n",
    "        'https://api.open-meteo.com/v1/forecast'\n",
    "        f'?latitude={lat}&longitude={lon}&hourly=temperature_2m,wind_speed_10m'\n",
    "        f'&start_date={start.date()}&end_date={end.date()}&timezone=UTC'\n",
    "    )\n",
    "    try:\n",
    "        r = requests.get(url, timeout=30)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "        times = pd.to_datetime(data['hourly']['time'])\n",
    "        return pd.DataFrame({\n",
    "            'temperature': data['hourly']['temperature_2m'],\n",
    "            'wind_speed': data['hourly']['wind_speed_10m']\n",
    "        }, index=times)\n",
    "    except Exception as e:\n",
    "        print(f'Could not download weather data: {e}. Returning dummy data')\n",
    "        idx = pd.date_range(start, end, freq='H', inclusive='left')\n",
    "        return pd.DataFrame({'temperature': 0.0, 'wind_speed': 0.0}, index=idx)\n",
    "\n",
    "\n",
    "def fetch_holidays(start: datetime, end: datetime) -> pd.DataFrame:\n",
    "    if holidays is None:\n",
    "        raise RuntimeError('holidays library not installed')\n",
    "    ch_holidays = holidays.CH(years=range(start.year, end.year + 1))\n",
    "    idx = pd.date_range(start, end, freq='D')\n",
    "    flags = [1 if day.date() in ch_holidays else 0 for day in idx]\n",
    "    return pd.DataFrame({'holiday': flags}, index=idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaa3ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def merge_additional_data(prices: pd.DataFrame,\n",
    "                          load: pd.DataFrame | None = None,\n",
    "                          weather: pd.DataFrame | None = None,\n",
    "                          holidays_df: pd.DataFrame | None = None) -> pd.DataFrame:\n",
    "    df = prices.resample('H').mean()\n",
    "    if load is not None:\n",
    "        df = df.join(load, how='left')\n",
    "    if weather is not None:\n",
    "        df = df.join(weather, how='left')\n",
    "    if holidays_df is not None:\n",
    "        df = df.join(holidays_df, how='left')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53db8d9e",
   "metadata": {},
   "source": [
    "## Download and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f3be8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "end = datetime.utcnow()\n",
    "start = end - timedelta(days=90)\n",
    "price_frames = []\n",
    "current = start.replace(day=1)\n",
    "while current <= end:\n",
    "    path = download_monthly_price(current.year, current.month)\n",
    "    price_frames.append(load_price_file(path))\n",
    "    if current.month == 12:\n",
    "        current = current.replace(year=current.year + 1, month=1)\n",
    "    else:\n",
    "        current = current.replace(month=current.month + 1)\n",
    "prices = pd.concat(price_frames).sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f15aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "entsoe_token = os.getenv('ENTSOE_TOKEN', '')\n",
    "if entsoe_token:\n",
    "    load = fetch_entsoe_load(prices.index.min(), prices.index.max() + pd.Timedelta(hours=1), entsoe_token)\n",
    "else:\n",
    "    print('ENTSOE_TOKEN not set. Using dummy load data')\n",
    "    load = fetch_entsoe_load(prices.index.min(), prices.index.max() + pd.Timedelta(hours=1), entsoe_token)\n",
    "\n",
    "weather = fetch_weather(prices.index.min(), prices.index.max() + pd.Timedelta(hours=1), lat=46.8, lon=8.3)\n",
    "holidays_df = fetch_holidays(prices.index.min(), prices.index.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6adc2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "merged = merge_additional_data(prices, load, weather, holidays_df)\n",
    "features = add_basic_features(merged).join(merged[['load', 'temperature', 'wind_speed', 'holiday']])\n",
    "features = features.dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac61461",
   "metadata": {},
   "source": [
    "## Train model using all available data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668aaafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "X = features[[\n",
    "    'hour', 'weekday', 'month', 'dayofyear', 'lag_price',\n",
    "    'rolling_mean_24h', 'rolling_std_24h', 'load',\n",
    "    'temperature', 'wind_speed', 'holiday'\n",
    "]]\n",
    "y = features['PositivePrice']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "model = GradientBoostingRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print('MAE:', mean_absolute_error(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3e62a1",
   "metadata": {},
   "source": [
    "This notebook demonstrates the full pipeline from data acquisition to model training in one place."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
